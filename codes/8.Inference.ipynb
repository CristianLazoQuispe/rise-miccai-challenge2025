{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3cfa9f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "from typing import List, Iterable, Optional\n",
    "import tqdm\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Optional, Dict, Any\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "\n",
    "try:\n",
    "    import nibabel as nib  # solo usado si transform es None\n",
    "except ImportError:\n",
    "    nib = None\n",
    "\n",
    "\n",
    "class MRIDataset3D(Dataset):\n",
    "    \"\"\"\n",
    "    Minimal 3D MRI dataset that plays nicely with MONAI dict transforms.\n",
    "\n",
    "    - Expects a DataFrame with column 'filepath' and, if training, 'filepath_label'.\n",
    "    - If `transform` is provided, it should accept/return a dict with keys\n",
    "      'image' and (optionally) 'label' (e.g., MONAI's Compose with LoadImaged, etc).\n",
    "    - If `transform` is None, falls back to nibabel loading and returns torch tensors.\n",
    "\n",
    "    Returns (by default) a dict with:\n",
    "        {'image': Tensor [1,D,H,W], 'label': Tensor [1,D,H,W] (if available),\n",
    "         'image_path': str, 'label_path': Optional[str]}\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        is_train: bool = True,\n",
    "        transform: Optional[callable] = None,\n",
    "    ) -> None:\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.is_train = is_train\n",
    "        self.transform = transform\n",
    "\n",
    "        self._has_label = self.is_train and (\"filepath_label\" in self.df.columns)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, Any]:\n",
    "        row = self.df.iloc[idx]\n",
    "        #print(\"row:\",row )\n",
    "        img_path = row[\"filepath\"]\n",
    "        sample: Dict[str, Any] = {\"image\": img_path, \"image_path\": img_path}\n",
    "\n",
    "        if self._has_label and pd.notna(row.get(\"filepath_label\", None)):\n",
    "            lab_path = row[\"filepath_label\"]\n",
    "            sample[\"label\"] = lab_path\n",
    "            sample[\"label_path\"] = lab_path\n",
    "        else:\n",
    "            sample[\"label_path\"] = \"\"\n",
    "\n",
    "        #print(\"sample:\",sample )\n",
    "        if self.transform is not None:\n",
    "            # MONAI-style: transform loads and returns tensors/MetaTensors\n",
    "            out = self.transform(sample)\n",
    "            # ensure the meta paths stay available\n",
    "            out.setdefault(\"image_path\", img_path)\n",
    "            out.setdefault(\"label_path\", sample.get(\"label_path\", \"\"))\n",
    "            return out\n",
    "\n",
    "        # Fallback path: no transform -> direct nibabel load\n",
    "        img_t = self._fallback_load(img_path)\n",
    "        out = {\"image\": img_t, \"image_path\": img_path}\n",
    "\n",
    "        if sample[\"label_path\"] is not None:\n",
    "            lab_t = self._fallback_load_label(sample[\"label_path\"])\n",
    "            out[\"label\"] = lab_t\n",
    "            out[\"label_path\"] = sample[\"label_path\"]\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953e8610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Inference MONAI 3D (0/1/2)\n",
    "# SWI + Invertd + Ensemble\n",
    "# =========================\n",
    "import os, re, copy\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from monai.data import Dataset, decollate_batch\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImaged, EnsureChannelFirstd, Orientationd, Spacingd,\n",
    "    ScaleIntensityRanged, EnsureTyped, CropForegroundd, Resized, Invertd\n",
    ")\n",
    "\n",
    "# ---------- Constantes (ajústalas a lo entrenado) ----------\n",
    "SPACING      = (1.0, 1.0, 1.0)\n",
    "SPATIAL_SIZE = (96, 96, 96)\n",
    "ROI_SIZE     = SPATIAL_SIZE\n",
    "OVERLAP      = 0.25\n",
    "SW_BATCH     = 2\n",
    "N_CLASSES    = 3\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ---------- Modelo ----------\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "try:\n",
    "    from src.models import get_model  # tu UNeST\n",
    "except Exception:\n",
    "    get_model = None\n",
    "\n",
    "def create_model(model_name=\"unest\"):\n",
    "    model_name = model_name.lower()\n",
    "    if model_name == \"unet\":\n",
    "        from monai.networks.nets import UNet\n",
    "        return UNet(\n",
    "            spatial_dims=3, in_channels=1, out_channels=N_CLASSES,\n",
    "            channels=(16, 32, 64, 128), strides=(2, 2, 2)\n",
    "        ).to(DEVICE).eval()\n",
    "    elif model_name == \"unest\":\n",
    "        assert get_model is not None, \"No se encontró get_model() para UNeST.\"\n",
    "        return get_model(name=\"unest\", num_classes=N_CLASSES, device=str(DEVICE)).eval()\n",
    "    else:\n",
    "        raise ValueError(f\"Modelo no soportado: {model_name}\")\n",
    "\n",
    "# ---------- Transforms de TEST (mismos que validación) ----------\n",
    "def get_test_transforms():\n",
    "    return Compose([\n",
    "        LoadImaged(keys=[\"image\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\"]),\n",
    "        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
    "        CropForegroundd(keys=[\"image\"], source_key=\"image\", allow_smaller=True),\n",
    "        Spacingd(keys=[\"image\"], pixdim=SPACING, mode=(\"bilinear\",)),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=0.0, a_max=15.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "        Resized(keys=[\"image\"], spatial_size=SPATIAL_SIZE, mode=(\"trilinear\",)),\n",
    "        EnsureTyped(keys=[\"image\"], track_meta=True),\n",
    "    ])\n",
    "\n",
    "def get_val_transforms():\n",
    "    return Compose([\n",
    "        LoadImaged(keys=[\"image\",\"label\"]),\n",
    "        EnsureChannelFirstd(keys=[\"image\",\"label\"]),\n",
    "        Orientationd(keys=[\"image\",\"label\"], axcodes=\"RAS\"),\n",
    "        CropForegroundd(keys=[\"image\",\"label\"], source_key=\"image\", allow_smaller=True),\n",
    "        Spacingd(keys=[\"image\",\"label\"], pixdim=SPACING, mode=(\"bilinear\",\"nearest\")),\n",
    "        ScaleIntensityRanged(keys=[\"image\"], a_min=0.0, a_max=15.0, b_min=0.0, b_max=1.0, clip=True),\n",
    "        Resized(keys=[\"image\",\"label\"], spatial_size=SPATIAL_SIZE, mode=(\"trilinear\",\"nearest\")),\n",
    "        EnsureTyped(keys=[\"image\",\"label\"], track_meta=True),\n",
    "    ])\n",
    "\n",
    "\n",
    "# ---------- Dataset de TEST ----------\n",
    "class MRIDataset3DTest(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame, transform=None):\n",
    "        data = []\n",
    "        for _, r in df.iterrows():\n",
    "            item = {\"image\": r[\"filepath\"],\"filepath\": r[\"filepath\"]}\n",
    "            # si tienes columna opcional con máscara cerebral:\n",
    "            if \"brainmask_path\" in r and isinstance(r[\"brainmask_path\"], str):\n",
    "                item[\"brainmask_path\"] = r[\"brainmask_path\"]\n",
    "            # guarda ID si viene en el CSV para nombrar salida\n",
    "            if \"ID\" in r:\n",
    "                item[\"ID\"] = r[\"ID\"]\n",
    "            data.append(item)\n",
    "        super().__init__(data, transform=transform)\n",
    "\n",
    "# ---------- Utilidades ----------\n",
    "def build_outname(subject_id_or_path):\n",
    "    \"\"\"\n",
    "    Construye LISAHF{ID}segprediction.nii.gz.\n",
    "    Si no hay 'ID', extrae dígitos del filename.\n",
    "    \"\"\"\n",
    "    base = str(subject_id_or_path)\n",
    "    nums = re.findall(r\"\\d+\", base)\n",
    "    nid  = nums[-1] if nums else base\n",
    "    return f\"LISAHF{nid}segprediction.nii.gz\"\n",
    "\n",
    "def load_models(models_root, model_name):\n",
    "    \"\"\"Carga todos los folds ./fold_*/best_model.pth\"\"\"\n",
    "    fold_dirs = []\n",
    "    for d in sorted(os.listdir(models_root)):\n",
    "        p = os.path.join(models_root, d)\n",
    "        if os.path.isdir(p) and d.lower().startswith(\"fold_\") and os.path.exists(os.path.join(p, \"best_model.pth\")):\n",
    "            fold_dirs.append(p)\n",
    "    assert len(fold_dirs) > 0, f\"No se encontraron checkpoints en {models_root}/fold_*/best_model.pth\"\n",
    "    models = []\n",
    "    for fd in fold_dirs:\n",
    "        ckpt = os.path.join(fd, \"best_model.pth\")\n",
    "        model = create_model(model_name)\n",
    "        print(\"Leyendo checkpoint:\", ckpt)\n",
    "        model.load_state_dict(torch.load(ckpt, map_location=DEVICE))\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    return fold_dirs, models\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "def _first_meta(meta_dict):\n",
    "    \"\"\"Convierte dict de listas (B=1) a dict por-elemento.\"\"\"\n",
    "    out = {}\n",
    "    for k, v in meta_dict.items():\n",
    "        # en MONAI, meta suele ser lista por batch; tomamos el 0 si es lista/tupla\n",
    "        out[k] = v[0] if isinstance(v, (list, tuple)) else v\n",
    "    return out\n",
    "\n",
    "# ---------- Inference principal ----------\n",
    "def run_inference(\n",
    "    df_test_csv,\n",
    "    models_root,\n",
    "    output_dir,\n",
    "    model_name=\"unest\",\n",
    "    mask_threshold=0.0,\n",
    "    save_per_fold=True,\n",
    "):\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    if save_per_fold:\n",
    "        os.makedirs(os.path.join(output_dir, \"per_fold\"), exist_ok=True)\n",
    "\n",
    "    # 1) Carga DF y dataset\n",
    "    df_test = pd.read_csv(df_test_csv)\n",
    "    assert \"filepath\" in df_test.columns, \"El CSV de test debe tener columna 'filepath'.\"\n",
    "    test_tfm = get_test_transforms()\n",
    "    #test_ds  = MRIDataset3DTest(df_test, transform=test_tfm)\n",
    "    test_ds   = MRIDataset3D(df_test, is_train=False,  transform=test_tfm)\n",
    "    test_loader = DataLoader(test_ds, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)\n",
    "\n",
    "    # 2) Carga modelos (todos los folds)\n",
    "    fold_dirs, models = load_models(models_root, model_name)\n",
    "    print(f\"Usando {len(models)} folds:\", fold_dirs)\n",
    "\n",
    "    # 3) Invertd para probs (lo creamos una vez y lo reusamos por sample)\n",
    "    #    OJO: se usa el MISMO objeto 'test_tfm' que aplicó el dataset\n",
    "    def make_inv_for_elem(elem):\n",
    "        # Invertd leerá 'pred_meta_dict' y 'image_meta_dict'\n",
    "        return Invertd(\n",
    "            keys=\"pred\",\n",
    "            transform=test_tfm,\n",
    "            orig_keys=\"image\",\n",
    "            meta_keys=\"pred_meta_dict\",\n",
    "            orig_meta_keys=\"image_meta_dict\",\n",
    "            nearest_interp=False,   # LINEAL para PROBS\n",
    "            to_tensor=True,\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    with torch.no_grad():\n",
    "      for i, batch in enumerate(test_loader):\n",
    "          # ----- rutas / affine en original -----\n",
    "          # usa la columna \"filepath\" que pusiste en el Dataset de test\n",
    "          img_path = batch[\"image_path\"][0] if isinstance(batch[\"image_path\"], list) else batch[\"image_path\"]\n",
    "          nii      = nib.load(img_path)\n",
    "          orig_img = nii.get_fdata()\n",
    "          orig_aff = nii.affine\n",
    "\n",
    "          # nombre de salida\n",
    "          subject_id = batch.get(\"ID\", [None])[0] if \"ID\" in batch else None\n",
    "          out_name   = build_outname(subject_id if subject_id is not None else img_path)\n",
    "\n",
    "          # ----- EXTRAER ELEMENTO 0 (sin batch) -----\n",
    "          # imagen procesada (MetaTensor) sin dimensión de batch: (1, d, h, w)\n",
    "          e_img  = batch[\"image\"][0]\n",
    "          # metadatos por elemento\n",
    "          e_meta = _first_meta(batch[\"image\"].meta)\n",
    "\n",
    "          prob_sum = None\n",
    "\n",
    "          for k, model in enumerate(models, start=1):\n",
    "              # ---- inferencia SWI en espacio procesado ----\n",
    "              with autocast():\n",
    "                  # añade de nuevo el batch para el predictor: (1, 1, d, h, w)\n",
    "                  logits = sliding_window_inference(\n",
    "                      inputs=e_img.unsqueeze(0).to(DEVICE),\n",
    "                      roi_size=ROI_SIZE,\n",
    "                      sw_batch_size=SW_BATCH,\n",
    "                      predictor=model,\n",
    "                      #overlap=OVERLAP,\n",
    "                      mode=\"constant\",#gaussian\",\n",
    "                  )\n",
    "\n",
    "              # softmax y QUITAR batch -> (C, d, h, w)\n",
    "              probs_proc_el = torch.softmax(logits, dim=1).cpu()[0]\n",
    "\n",
    "              # ---- Invertd: usa el MISMO pipeline y los metadatos del elemento ----\n",
    "              elem = {\n",
    "                  \"image\": e_img,                   # (1, d, h, w) MetaTensor\n",
    "                  \"image_meta_dict\": e_meta,        # meta de UN SOLO elemento\n",
    "                  \"pred\": probs_proc_el,            # (C, d, h, w)  << SIN batch\n",
    "                  \"pred_meta_dict\": deepcopy(e_meta),\n",
    "              }\n",
    "              inv = Invertd(\n",
    "                  keys=\"pred\",\n",
    "                  transform=test_tfm,       # el pipeline de test\n",
    "                  orig_keys=\"image\",\n",
    "                  meta_keys=\"pred_meta_dict\",\n",
    "                  orig_meta_keys=\"image_meta_dict\",\n",
    "                  nearest_interp=False,     # lineal para probabilidades\n",
    "                  to_tensor=True,\n",
    "              )\n",
    "              elem = inv(elem)\n",
    "\n",
    "              # probabilidades en ESPACIO ORIGINAL: (C, Z, Y, X)\n",
    "              probs_orig = elem[\"pred\"].numpy()\n",
    "              prob_sum = probs_orig if prob_sum is None else (prob_sum + probs_orig)\n",
    "\n",
    "              # ---- guardado por-fold (opcional) ----\n",
    "              if save_per_fold:\n",
    "                  lab_k = np.argmax(probs_orig, axis=0).astype(np.uint8)\n",
    "                  # máscara cerebral en ORIGINAL\n",
    "                  if (\"brainmask_path\" in batch and isinstance(batch[\"brainmask_path\"][0], str)\n",
    "                          and os.path.exists(batch[\"brainmask_path\"][0])):\n",
    "                      bm = (nib.load(batch[\"brainmask_path\"][0]).get_fdata() > 0).astype(np.uint8)\n",
    "                  else:\n",
    "                      bm = (orig_img > mask_threshold).astype(np.uint8)\n",
    "                  lab_k = (lab_k * (bm > 0)).astype(np.uint8)\n",
    "\n",
    "                  fold_dir  = os.path.join(output_dir, \"per_fold\", f\"fold_{k}\")\n",
    "                  os.makedirs(fold_dir, exist_ok=True)\n",
    "                  out_path_k = os.path.join(fold_dir, out_name.replace(\".nii.gz\", f\"_fold{k}.nii.gz\"))\n",
    "                  nib.save(nib.Nifti1Image(lab_k, orig_aff), out_path_k)\n",
    "\n",
    "          # ---- ensamble final ----\n",
    "          prob_avg = prob_sum / float(len(models))\n",
    "          pred_lab = np.argmax(prob_avg, axis=0).astype(np.uint8)\n",
    "\n",
    "          # máscara final (original)\n",
    "          if (\"brainmask_path\" in batch and isinstance(batch[\"brainmask_path\"][0], str)\n",
    "                  and os.path.exists(batch[\"brainmask_path\"][0])):\n",
    "              brain_mask = (nib.load(batch[\"brainmask_path\"][0]).get_fdata() > 0).astype(np.uint8)\n",
    "          else:\n",
    "              brain_mask = (orig_img > mask_threshold).astype(np.uint8)\n",
    "          pred_lab = (pred_lab * (brain_mask > 0)).astype(np.uint8)\n",
    "\n",
    "          out_path = os.path.join(output_dir, out_name)\n",
    "          nib.save(nib.Nifti1Image(pred_lab, orig_aff), out_path)\n",
    "          print(f\"[{i+1}/{len(test_ds)}] guardado: {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32bcac57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leyendo checkpoint: /data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/fold_models/fold_1/best_model.pth\n",
      "Leyendo checkpoint: /data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/fold_models/fold_2/best_model.pth\n",
      "Leyendo checkpoint: /data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/fold_models/fold_3/best_model.pth\n",
      "Leyendo checkpoint: /data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/fold_models/fold_4/best_model.pth\n",
      "Leyendo checkpoint: /data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/fold_models/fold_5/best_model.pth\n",
      "Usando 5 folds: ['/data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/fold_models/fold_1', '/data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/fold_models/fold_2', '/data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/fold_models/fold_3', '/data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/fold_models/fold_4', '/data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/fold_models/fold_5']\n",
      "[1/12] guardado: /data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/predictions/LISAHF0001segprediction.nii.gz\n",
      "[2/12] guardado: /data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/predictions/LISAHF0004segprediction.nii.gz\n",
      "[3/12] guardado: /data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/predictions/LISAHF0005segprediction.nii.gz\n",
      "[4/12] guardado: /data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/predictions/LISAHF0003segprediction.nii.gz\n",
      "[5/12] guardado: /data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/predictions/LISAHF0002segprediction.nii.gz\n",
      "[6/12] guardado: /data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/predictions/LISAHF0006segprediction.nii.gz\n",
      "[7/12] guardado: /data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/predictions/LISAHF0007segprediction.nii.gz\n",
      "[8/12] guardado: /data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/predictions/LISAHF0008segprediction.nii.gz\n",
      "[9/12] guardado: /data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/predictions/LISAHF0009segprediction.nii.gz\n",
      "[10/12] guardado: /data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/predictions/LISAHF0010segprediction.nii.gz\n",
      "[11/12] guardado: /data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/predictions/LISAHF0011segprediction.nii.gz\n",
      "[12/12] guardado: /data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/predictions/LISAHF0012segprediction.nii.gz\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df_test_csv = \"../results/preprocessed_data/task2/df_test_hipp.csv\"\n",
    "\n",
    "run_inference(\n",
    "    df_test_csv=df_test_csv,\n",
    "    #models_root=\"./fold_models\",   # donde están fold_1/best_model.pth, fold_2/..., etc.\n",
    "    models_root=\"/data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/fold_models\",\n",
    "    output_dir=\"/data/cristian/projects/med_data/rise-miccai/task-2/3d_models/predictions/model_unest_03_test/predictions\",\n",
    "    model_name=\"unest\",            # o \"unet\"\n",
    "    mask_threshold=0.0,            # si no tienes brainmask externa\n",
    "    save_per_fold=True,            # guarda también por-fold en subcarpetas\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add370d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e104212",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_cris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
